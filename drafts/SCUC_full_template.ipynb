{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a866e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#  Constants & cache                                                          \u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     17\u001b[39m INSTANCES_URL = \u001b[33m\"\u001b[39m\u001b[33mhttps://axavier.org/UnitCommitment.jl/0.4/instances\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m _CACHE = Path(\u001b[34;43m__file__\u001b[39;49m).resolve().parent / \u001b[33m\"\u001b[39m\u001b[33minstances\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m _CACHE.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#  Data classes (faithful to UnitCommitment.jl)                               \u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Sequence, Union, Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#  Constants & cache                                                          \n",
    "# ---------------------------------------------------------------------------\n",
    "INSTANCES_URL = \"https://axavier.org/UnitCommitment.jl/0.4/instances\"\n",
    "_CACHE = Path(__file__).resolve().parent / \"instances\"\n",
    "_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#  Data classes (faithful to UnitCommitment.jl)                               \n",
    "# ---------------------------------------------------------------------------\n",
    "Number = Union[int, float]\n",
    "Series = List[Number]\n",
    "\n",
    "@dataclass\n",
    "class CostSegment:\n",
    "    amount: Series\n",
    "    cost: Series\n",
    "\n",
    "@dataclass\n",
    "class StartupCategory:\n",
    "    delay_steps: int\n",
    "    cost: float\n",
    "\n",
    "@dataclass\n",
    "class Bus:\n",
    "    name: str\n",
    "    index: int\n",
    "    load: Series\n",
    "    thermal_units: List[\"ThermalUnit\"] = field(default_factory=list)\n",
    "    price_sensitive_loads: List[\"PriceSensitiveLoad\"] = field(default_factory=list)\n",
    "    profiled_units: List[\"ProfiledUnit\"] = field(default_factory=list)\n",
    "    storage_units: List[\"StorageUnit\"] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class Reserve:\n",
    "    name: str\n",
    "    type: str  # \"spinning\", \"flex-up\", etc.\n",
    "    amount: Series\n",
    "    thermal_units: List[\"ThermalUnit\"]\n",
    "    shortfall_penalty: float\n",
    "\n",
    "@dataclass\n",
    "class ThermalUnit:\n",
    "    name: str\n",
    "    bus: Bus\n",
    "    max_power: Series\n",
    "    min_power: Series\n",
    "    must_run: Series\n",
    "    min_power_cost: Series\n",
    "    segments: List[CostSegment]\n",
    "    min_up: int\n",
    "    min_down: int\n",
    "    ramp_up: float\n",
    "    ramp_down: float\n",
    "    startup_limit: float\n",
    "    shutdown_limit: float\n",
    "    initial_status: Optional[int]\n",
    "    initial_power: Optional[float]\n",
    "    startup_categories: List[StartupCategory]\n",
    "    reserves: List[Reserve]\n",
    "    commitment_status: List[Optional[bool]]\n",
    "\n",
    "@dataclass\n",
    "class ProfiledUnit:\n",
    "    name: str\n",
    "    bus: Bus\n",
    "    min_power: Series\n",
    "    max_power: Series\n",
    "    cost: Series\n",
    "\n",
    "@dataclass\n",
    "class StorageUnit:\n",
    "    name: str\n",
    "    bus: Bus\n",
    "    min_level: Series\n",
    "    max_level: Series\n",
    "    simultaneous: Series\n",
    "    charge_cost: Series\n",
    "    discharge_cost: Series\n",
    "    charge_eff: Series\n",
    "    discharge_eff: Series\n",
    "    loss_factor: Series\n",
    "    min_charge: Series\n",
    "    max_charge: Series\n",
    "    min_discharge: Series\n",
    "    max_discharge: Series\n",
    "    initial_level: float\n",
    "    last_min: float\n",
    "    last_max: float\n",
    "\n",
    "@dataclass\n",
    "class TransmissionLine:\n",
    "    name: str\n",
    "    index: int\n",
    "    source: Bus\n",
    "    target: Bus\n",
    "    susceptance: float\n",
    "    normal_limit: Series\n",
    "    emergency_limit: Series\n",
    "    flow_penalty: Series\n",
    "\n",
    "@dataclass\n",
    "class Contingency:\n",
    "    name: str\n",
    "    lines: List[TransmissionLine]\n",
    "    units: List[ThermalUnit]\n",
    "\n",
    "@dataclass\n",
    "class PriceSensitiveLoad:\n",
    "    name: str\n",
    "    bus: Bus\n",
    "    demand: Series\n",
    "    revenue: Series\n",
    "\n",
    "@dataclass\n",
    "class UnitCommitmentScenario:\n",
    "    name: str\n",
    "    probability: float\n",
    "    buses_by_name: Dict[str, Bus]\n",
    "    buses: List[Bus]\n",
    "    contingencies_by_name: Dict[str, Contingency]\n",
    "    contingencies: List[Contingency]\n",
    "    lines_by_name: Dict[str, TransmissionLine]\n",
    "    lines: List[TransmissionLine]\n",
    "    power_balance_penalty: Series\n",
    "    price_sensitive_loads_by_name: Dict[str, PriceSensitiveLoad]\n",
    "    price_sensitive_loads: List[PriceSensitiveLoad]\n",
    "    reserves: List[Reserve]\n",
    "    reserves_by_name: Dict[str, Reserve]\n",
    "    time: int\n",
    "    time_step: int\n",
    "    thermal_units_by_name: Dict[str, ThermalUnit]\n",
    "    thermal_units: List[ThermalUnit]\n",
    "    profiled_units_by_name: Dict[str, ProfiledUnit]\n",
    "    profiled_units: List[ProfiledUnit]\n",
    "    storage_units_by_name: Dict[str, StorageUnit]\n",
    "    storage_units: List[StorageUnit]\n",
    "    isf: sp.csr_matrix\n",
    "    lodf: sp.csr_matrix\n",
    "    source: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class UnitCommitmentInstance:\n",
    "    time: int\n",
    "    scenarios: List[UnitCommitmentScenario]\n",
    "\n",
    "    @property\n",
    "    def deterministic(self) -> UnitCommitmentScenario:\n",
    "        if len(self.scenarios) != 1:\n",
    "            raise ValueError(\"Instance is stochastic; pick a scenario explicitly\")\n",
    "        return self.scenarios[0]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#  Utility helpers                                                            \n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def _download(url: str, dst: Path, chunk: int = 1 << 20) -> None:\n",
    "    with requests.get(url, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"content-length\", 0))\n",
    "        with dst.open(\"wb\") as fh, tqdm(total=total, unit=\"B\", unit_scale=True, disable=total == 0) as bar:\n",
    "            for blk in r.iter_content(chunk_size=chunk):\n",
    "                fh.write(blk)\n",
    "                bar.update(len(blk))\n",
    "\n",
    "def read_benchmark(name: str) -> UnitCommitmentInstance:\n",
    "    gz_name = f\"{name}.json.gz\"\n",
    "    local = _CACHE / gz_name\n",
    "    if not local.exists():\n",
    "        print(f\"Downloading {gz_name}…\")\n",
    "        _download(f\"{INSTANCES_URL}/{gz_name}\", local)\n",
    "    return read(local)\n",
    "\n",
    "def _read_json(path: Union[str, Path]) -> dict:\n",
    "    path = Path(path)\n",
    "    if str(path).endswith(\".gz\"):\n",
    "        with gzip.open(path, \"rt\", encoding=\"utf-8\") as fh:\n",
    "            return json.load(fh)\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "        return json.load(fh)\n",
    "\n",
    "# scalar / timeseries helpers\n",
    "\n",
    "def _scalar(val, default=None):\n",
    "    return default if val is None else val\n",
    "\n",
    "def _timeseries(val, T: int, *, default=None):\n",
    "    if val is None:\n",
    "        return default if default is not None else [None] * T\n",
    "    return val if isinstance(val, list) else [val] * T\n",
    "\n",
    "# (migrations omitted for brevity – assume files are v0.4 already)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#  JSON ➜ objects (shortened from earlier)                                    \n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def _from_json(j: dict) -> UnitCommitmentScenario:\n",
    "    # Only supports v0.4 datasets (all benchmarks ≥0.4)\n",
    "    par = j[\"Parameters\"]\n",
    "    time_horizon = int(par[\"Time horizon (min)\"])\n",
    "    time_step = int(_scalar(par.get(\"Time step (min)\"), 60))\n",
    "    T = time_horizon // time_step\n",
    "\n",
    "    # Build buses\n",
    "    buses: List[Bus] = []\n",
    "    name_to_bus = {}\n",
    "    for idx, (bname, bdict) in enumerate(j[\"Buses\"].items(), start=1):\n",
    "        bus = Bus(name=bname, index=idx, load=_timeseries(bdict[\"Load (MW)\"], T))\n",
    "        buses.append(bus)\n",
    "        name_to_bus[bname] = bus\n",
    "\n",
    "    # Reserves\n",
    "    reserves: List[Reserve] = []\n",
    "    name_to_reserve = {}\n",
    "    for rname, rdict in j.get(\"Reserves\", {}).items():\n",
    "        r = Reserve(name=rname, type=rdict[\"Type\"].lower(), amount=_timeseries(rdict[\"Amount (MW)\"], T), thermal_units=[], shortfall_penalty=_scalar(rdict.get(\"Shortfall penalty ($/MW)\"), 10))\n",
    "        reserves.append(r)\n",
    "        name_to_reserve[rname] = r\n",
    "\n",
    "    # Generators (thermal + profiled)\n",
    "    thermal_units: List[ThermalUnit] = []\n",
    "    profiled_units: List[ProfiledUnit] = []\n",
    "    name_to_unit = {}\n",
    "    for gname, gdict in j[\"Generators\"].items():\n",
    "        bus = name_to_bus[gdict[\"Bus\"]]\n",
    "        if gdict[\"Type\"].lower() == \"thermal\":\n",
    "            curve_mw = gdict[\"Production cost curve (MW)\"]\n",
    "            curve_cost = gdict[\"Production cost curve ($)\"]\n",
    "            K = len(curve_mw)\n",
    "            curve_mw = np.column_stack([_timeseries(curve_mw[k], T) for k in range(K)])\n",
    "            curve_cost = np.column_stack([_timeseries(curve_cost[k], T) for k in range(K)])\n",
    "            min_power = curve_mw[:, 0].tolist()\n",
    "            max_power = curve_mw[:, -1].tolist()\n",
    "            min_power_cost = curve_cost[:, 0].tolist()\n",
    "            segments = []\n",
    "            for k in range(1, K):\n",
    "                amount = (curve_mw[:, k] - curve_mw[:, k - 1]).tolist()\n",
    "                cost = ((curve_cost[:, k] - curve_cost[:, k - 1]) / np.maximum(amount, 1e-9)).tolist()\n",
    "                segments.append(CostSegment(amount, cost))\n",
    "            tu = ThermalUnit(\n",
    "                name=gname,\n",
    "                bus=bus,\n",
    "                max_power=max_power,\n",
    "                min_power=min_power,\n",
    "                must_run=_timeseries(gdict.get(\"Must run?\"), T, default=[False] * T),\n",
    "                min_power_cost=min_power_cost,\n",
    "                segments=segments,\n",
    "                min_up=int(_scalar(gdict.get(\"Minimum uptime (h)\"), 1)),\n",
    "                min_down=int(_scalar(gdict.get(\"Minimum downtime (h)\"), 1)),\n",
    "                ramp_up=_scalar(gdict.get(\"Ramp up limit (MW)\"), 1e6),\n",
    "                ramp_down=_scalar(gdict.get(\"Ramp down limit (MW)\"), 1e6),\n",
    "                startup_limit=_scalar(gdict.get(\"Startup limit (MW)\"), 1e6),\n",
    "                shutdown_limit=_scalar(gdict.get(\"Shutdown limit (MW)\"), 1e6),\n",
    "                initial_status=int(_scalar(gdict.get(\"Initial status (h)\"), 0)),\n",
    "                initial_power=_scalar(gdict.get(\"Initial power (MW)\"), 0.0),\n",
    "                startup_categories=[StartupCategory(delay_steps=1, cost=0.0)],\n",
    "                reserves=[name_to_reserve[n] for n in gdict.get(\"Reserve eligibility\", [])],\n",
    "                commitment_status=_timeseries(gdict.get(\"Commitment status\"), T, default=[None] * T),\n",
    "            )\n",
    "            bus.thermal_units.append(tu)\n",
    "            for r in tu.reserves:\n",
    "                r.thermal_units.append(tu)\n",
    "            thermal_units.append(tu)\n",
    "            name_to_unit[gname] = tu\n",
    "        else:\n",
    "            pu = ProfiledUnit(name=gname, bus=bus, min_power=_timeseries(_scalar(gdict.get(\"Minimum power (MW)\"), 0.0), T), max_power=_timeseries(gdict[\"Maximum power (MW)\"], T), cost=_timeseries(gdict[\"Cost ($/MW)\"], T))\n",
    "            bus.profiled_units.append(pu)\n",
    "            profiled_units.append(pu)\n",
    "\n",
    "    # Lines\n",
    "    lines: List[TransmissionLine] = []\n",
    "    name_to_line = {}\n",
    "    for idx, (lname, ldict) in enumerate(j.get(\"Transmission lines\", {}).items(), start=1):\n",
    "        line = TransmissionLine(name=lname, index=idx, source=name_to_bus[ldict[\"Source bus\"]], target=name_to_bus[ldict[\"Target bus\"]], susceptance=float(ldict[\"Susceptance (S)\"]), normal_limit=_timeseries(ldict.get(\"Normal flow limit (MW)\"), T, default=[1e8] * T), emergency_limit=_timeseries(ldict.get(\"Emergency flow limit (MW)\"), T, default=[1e8] * T), flow_penalty=_timeseries(ldict.get(\"Flow limit penalty ($/MW)\"), T, default=[5000.0] * T))\n",
    "        lines.append(line)\n",
    "        name_to_line[lname] = line\n",
    "\n",
    "    # Contingencies (affects outaged lines & units)\n",
    "    contingencies: List[Contingency] = []\n",
    "    for cname, cdict in j.get(\"Contingencies\", {}).items():\n",
    "        contingencies.append(Contingency(name=cname, lines=[name_to_line[l] for l in cdict.get(\"Affected lines\", [])], units=[name_to_unit[u] for u in cdict.get(\"Affected units\", [])]))\n",
    "\n",
    "    # Price‑sensitive load\n",
    "    psloads: List[PriceSensitiveLoad] = []\n",
    "    for lname, ldict in j.get(\"Price-sensitive loads\", {}).items():\n",
    "        pl = PriceSensitiveLoad(name=lname, bus=name_to_bus[ldict[\"Bus\"]], demand=_timeseries(ldict[\"Demand (MW)\"], T), revenue=_timeseries(ldict[\"Revenue ($/MW)\"], T))\n",
    "        psloads.append(pl)\n",
    "        pl.bus.price_sensitive_loads.append(pl)\n",
    "\n",
    "    # Storage (omitted for brevity)\n",
    "    storage_units: List[StorageUnit] = []\n",
    "\n",
    "    isf = sp.csr_matrix((len(lines), len(buses) - 1), dtype=float)\n",
    "    lodf = sp.csr_matrix((len(lines), len(lines)), dtype=float)\n",
    "\n",
    "    sc = UnitCommitmentScenario(name=j[\"Parameters\"].get(\"Scenario name\", \"\"), probability=float(j[\"Parameters\"].get(\"Scenario weight\", 1)), buses_by_name={b.name: b for b in buses}, buses=buses, contingencies_by_name={c.name: c for c in contingencies}, contingencies=contingencies, lines_by_name={l.name: l for l in lines}, lines=lines, power_balance_penalty=_timeseries(j[\"Parameters\"].get(\"Power balance penalty ($/MW)\"), T, default=[1000.0] * T), price_sensitive_loads_by_name={pl.name: pl for pl in psloads}, price_sensitive_loads=psloads, reserves=reserves, reserves_by_name=name_to_reserve, time=T, time_step=time_step, thermal_units_by_name={tu.name: tu for tu in thermal_units}, thermal_units=thermal_units, profiled_units_by_name={pu.name: pu for pu in profiled_units}, profiled_units=profiled_units, storage_units_by_name={}, storage_units=storage_units, isf=isf, lodf=lodf)\n",
    "\n",
    "    return sc\n",
    "\n",
    "def read(path_or_paths: Union[str, Sequence[str]]) -> UnitCommitmentInstance:\n",
    "    if isinstance(path_or_paths, (list, tuple)):\n",
    "        scenarios = [_from_json(_read_json(p)) for p in path_or_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b57eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
